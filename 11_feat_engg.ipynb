{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A variety of resamples which I may or may not use\n",
    "df_hourly = df.set_index('timestamp').resample('H').mean().reset_index()\n",
    "df_daily = df.set_index('timestamp').resample('D').mean().reset_index()\n",
    "df_weekly = df.set_index('timestamp').resample('W').mean().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No need to take care of detrending"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# does it make sense to deseasonalize the data first before applying the algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are multiple approaches to deseasonalize a time series. These approaches are listed below:\n",
    "\n",
    "Take a moving average with length as the seasonal window. This will smoothen in series in the process.\n",
    "Seasonal difference the series (subtract the value of previous season from the current value).\n",
    "Divide the series by the seasonal index obtained from STL decomposition.\n",
    "\n",
    "If dividing by the seasonal index does not work well, we will take a log of the series and then do the deseasonalizing. We will later restore to the original scale by taking an exponential.\n",
    "\n",
    "# Time Series Decomposition\n",
    "result_mul = seasonal_decompose(df['Number of Passengers'], model='multiplicative', period=30)\n",
    "\n",
    "\n",
    "# Deseasonalize\n",
    "deseasonalized = df['Number of Passengers'].values / result_mul.seasonal\n",
    "\n",
    "\n",
    "# Plot\n",
    "plt.plot(deseasonalized)\n",
    "plt.title('Air Passengers Deseasonalized', fontsize=16)\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New features \n",
    "# Loop to cycle through both DataFrames\n",
    "for DataFrame in [df_hourly, df_daily]:\n",
    "    DataFrame['Weekday'] = (pd.Categorical(DataFrame['timestamp'].dt.strftime('%A'),\n",
    "                                           categories=['Monday', 'Tuesday', 'Wednesday', 'Thursday','Friday', 'Saturday', 'Sunday'])\n",
    "                           )\n",
    "    DataFrame['Hour'] = DataFrame['timestamp'].dt.hour\n",
    "    DataFrame['Day'] = DataFrame['timestamp'].dt.weekday\n",
    "    DataFrame['Month'] = DataFrame['timestamp'].dt.month\n",
    "    DataFrame['Year'] = DataFrame['timestamp'].dt.year\n",
    "    DataFrame['Month_day'] = DataFrame['timestamp'].dt.day\n",
    "    DataFrame['Lag'] = DataFrame['value'].shift(1)\n",
    "    DataFrame['Rolling_Mean'] = DataFrame['value'].rolling(7, min_periods=1).mean()\n",
    "    DataFrame = DataFrame.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['year'] = pd.DatetimeIndex(df['date']).year\n",
    "df['month'] = pd.DatetimeIndex(df['date']).month\n",
    "df['day'] = pd.DatetimeIndex(df['date']).day\n",
    "df['day_of_year'] = pd.DatetimeIndex(df['date']).dayofyear\n",
    "df['week_of_year'] = pd.DatetimeIndex(df['date']).weekofyear\n",
    "df['quarter'] = pd.DatetimeIndex(df['date']).quarter\n",
    "df['season'] = df['month'] % 12 // 3 + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1 Encoding Cyclical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_in_year = 12\n",
    "df['month_sin'] = np.sin(2*np.pi*df['month']/month_in_year)\n",
    "df['month_cos'] = np.cos(2*np.pi*df['month']/month_in_year)\n",
    "\n",
    "f, ax = plt.subplots(nrows=1, ncols=1, figsize=(6, 6))\n",
    "\n",
    "sns.scatterplot(x=df.month_sin, y=df.month_cos, color='dodgerblue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3 Lag\n",
    "\n",
    "We want to calculate each variable with a shift() (lag) to compare the correlationwith the other variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weeks_in_month = 4\n",
    "\n",
    "for column in core_columns:\n",
    "    df[f'{column}_seasonal_shift_b_2m'] = df[f'{column}_seasonal'].shift(-2 * weeks_in_month)\n",
    "    df[f'{column}_seasonal_shift_b_1m'] = df[f'{column}_seasonal'].shift(-1 * weeks_in_month)\n",
    "    df[f'{column}_seasonal_shift_1m'] = df[f'{column}_seasonal'].shift(1 * weeks_in_month)\n",
    "    df[f'{column}_seasonal_shift_2m'] = df[f'{column}_seasonal'].shift(2 * weeks_in_month)\n",
    "    df[f'{column}_seasonal_shift_3m'] = df[f'{column}_seasonal'].shift(3 * weeks_in_month)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "do a covariance histogram of each variable with its lagged variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(nrows=1, ncols=2, figsize=(16, 8))\n",
    "\n",
    "corrmat = df[core_columns].corr()\n",
    "\n",
    "sns.heatmap(corrmat, annot=True, vmin=-1, vmax=1, cmap='coolwarm_r', ax=ax[0])\n",
    "ax[0].set_title('Correlation Matrix of Core Features', fontsize=16)\n",
    "\n",
    "shifted_cols = [\n",
    "    'depth_to_groundwater_seasonal',         \n",
    "    'temperature_seasonal_shift_b_2m',\n",
    "    'drainage_volume_seasonal_shift_2m', \n",
    "    'river_hydrometry_seasonal_shift_3m'\n",
    "]\n",
    "corrmat = df[shifted_cols].corr()\n",
    "\n",
    "sns.heatmap(corrmat, annot=True, vmin=-1, vmax=1, cmap='coolwarm_r', ax=ax[1])\n",
    "ax[1].set_title('Correlation Matrix of Lagged Features', fontsize=16)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.1 Autocorrelation Analysis\n",
    "\n",
    "¶\n",
    "ACF and PACF plots: After a time series has been stationarized by differencing, the next step in fitting an ARIMA model is to determine whether AR or MA terms are needed to correct any autocorrelation that remains in the differenced series. Of course, with software like Statgraphics, you could just try some different combinations of terms and see what works best. But there is a more systematic way to do this. By looking at the autocorrelation function (ACF) and partial autocorrelation (PACF) plots of the differenced series, you can tentatively identify the numbers of AR and/or MA terms that are needed.\n",
    "\n",
    "Autocorrelation Function (ACF): P = Periods to lag for eg: (if P= 3 then we will use the three previous periods of our time series in the autoregressive portion of the calculation) P helps adjust the line that is being fitted to forecast the series. P corresponds with MA parameter\n",
    "Partial Autocorrelation Function (PACF): D = In an ARIMA model we transform a time series into stationary one(series without trend or seasonality) using differencing. D refers to the number of differencing transformations required by the time series to get stationary. D corresponds with AR parameter.\n",
    "Autocorrelation plots help in detecting seasonality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import autocorrelation_plot\n",
    "\n",
    "autocorrelation_plot(df['depth_to_groundwater_diff_1'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# to learn\n",
    "How to remove trend and seasonality- how to ensure stationarity of the data before using model like Arima"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ARIMA( p, d, q)\n",
    "\n",
    "p: Lag order (reference PACF in Autocorrelation Analysis)\n",
    "d: Degree of differencing. (reference Differencing in Stationarity)\n",
    "q: Order of moving average (check out ACF in Autocorrelation Analysis)\n",
    "Steps to analyze ARIMA\n",
    "Step 1 — Check stationarity: If a time series has a trend or seasonality component, it must be made stationary before we can use ARIMA to forecast. .\n",
    "Step 2 — Difference: If the time series is not stationary, it needs to be stationarized through differencing. Take the first difference, then check for stationarity. Take as many differences as it takes. Make sure you check seasonal differencing as well.\n",
    "Step 3 — Filter out a validation sample: This will be used to validate how accurate our model is. Use train test validation split to achieve this\n",
    "Step 4 — Select AR and MA terms: Use the ACF and PACF to decide whether to include an AR term(s), MA term(s), or both.\n",
    "Step 5 — Build the model: Build the model and set the number of periods to forecast to N (depends on your needs).\n",
    "Step 6 — Validate model: Compare the predicted values to the actuals in the validation sample."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
