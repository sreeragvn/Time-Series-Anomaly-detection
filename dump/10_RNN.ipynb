{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select and standardize data\n",
    "data_n = df[['value', 'hours', 'daylight', 'DayOfTheWeek', 'WeekDay']]\n",
    "min_max_scaler = preprocessing.StandardScaler()\n",
    "np_scaled = min_max_scaler.fit_transform(data_n)\n",
    "data_n = pd.DataFrame(np_scaled)\n",
    "\n",
    "# important parameters and train/test size\n",
    "prediction_time = 1 \n",
    "testdatasize = 1000\n",
    "unroll_length = 50\n",
    "testdatacut = testdatasize + unroll_length  + 1\n",
    "\n",
    "#train data\n",
    "x_train = data_n[0:-prediction_time-testdatacut].as_matrix()\n",
    "y_train = data_n[prediction_time:-testdatacut  ][0].as_matrix()\n",
    "\n",
    "# test data\n",
    "x_test = data_n[0-testdatacut:-prediction_time].as_matrix()\n",
    "y_test = data_n[prediction_time-testdatacut:  ][0].as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unroll: create sequence of 50 previous data points for each data points\n",
    "def unroll(data,sequence_length=24):\n",
    "    result = []\n",
    "    for index in range(len(data) - sequence_length):\n",
    "        result.append(data[index: index + sequence_length])\n",
    "    return np.asarray(result)\n",
    "\n",
    "# adapt the datasets for the sequence data shape\n",
    "x_train = unroll(x_train,unroll_length)\n",
    "x_test  = unroll(x_test,unroll_length)\n",
    "y_train = y_train[-x_train.shape[0]:]\n",
    "y_test  = y_test[-x_test.shape[0]:]\n",
    "\n",
    "# see the shape\n",
    "print(\"x_train\", x_train.shape)\n",
    "print(\"y_train\", y_train.shape)\n",
    "print(\"x_test\", x_test.shape)\n",
    "print(\"y_test\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specific libraries for RNN\n",
    "# keras is a high layer build on Tensorflow layer to stay in high level/easy implementation\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Sequential\n",
    "import time #helper libraries\n",
    "from keras.models import model_from_json\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(\n",
    "    input_dim=x_train.shape[-1],\n",
    "    output_dim=50,\n",
    "    return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(LSTM(\n",
    "    100,\n",
    "    return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(\n",
    "    units=1))\n",
    "model.add(Activation('linear'))\n",
    "\n",
    "start = time.time()\n",
    "model.compile(loss='mse', optimizer='rmsprop')\n",
    "print('compilation time : {}'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "#nb_epoch = 350\n",
    "\n",
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=3028,\n",
    "    nb_epoch=30,\n",
    "    validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the list of difference between prediction and test data\n",
    "loaded_model = model\n",
    "diff=[]\n",
    "ratio=[]\n",
    "p = loaded_model.predict(x_test)\n",
    "# predictions = lstm.predict_sequences_multiple(loaded_model, x_test, 50, 50)\n",
    "for u in range(len(y_test)):\n",
    "    pr = p[u][0]\n",
    "    ratio.append((y_test[u]/pr)-1)\n",
    "    diff.append(abs(y_test[u]- pr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the prediction and the reality (for the test data)\n",
    "fig, axs = plt.subplots()\n",
    "axs.plot(p,color='red', label='prediction')\n",
    "axs.plot(y_test,color='blue', label='y_test')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the most distant prediction/reality data points as anomalies\n",
    "diff = pd.Series(diff)\n",
    "number_of_outliers = int(outliers_fraction*len(diff))\n",
    "threshold = diff.nlargest(number_of_outliers).min()\n",
    "# data with anomaly label (test data part)\n",
    "test = (diff >= threshold).astype(int)\n",
    "# the training data part where we didn't predict anything (overfitting possible): no anomaly\n",
    "complement = pd.Series(0, index=np.arange(len(data_n)-testdatasize))\n",
    "# # add the data to the main\n",
    "df['anomaly27'] = complement.append(test, ignore_index='True')\n",
    "print(df['anomaly27'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualisation of anomaly throughout time (viz 1)\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "a = df.loc[df['anomaly27'] == 1, ['time_epoch', 'value']] #anomaly\n",
    "\n",
    "ax.plot(df['time_epoch'], df['value'], color='blue')\n",
    "ax.scatter(a['time_epoch'],a['value'], color='red')\n",
    "plt.axis([1.370*1e7, 1.405*1e7, 15,30])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
