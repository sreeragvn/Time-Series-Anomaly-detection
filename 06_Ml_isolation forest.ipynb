{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification and Regression Trees (CART)\n",
    "We can utilize the power and robustness of Decision Trees to identify outliers/anomalies in time series data.\n",
    "\n",
    "First, you can use supervised learning to teach trees to classify anomaly and non-anomaly data points. In order to do that, we’d need to have labeled anomaly data points, which you won’t find often outside of toy datasets.\n",
    "Unsupervised is what you need! We can use the Isolation Forest algorithm to predict whether a certain point is an outlier or not, without the help of any labeled dataset. Let’s see how.\n",
    "The main idea, which is different from other popular outlier detection methods, is that Isolation Forest explicitly identifies anomalies instead of profiling normal data points. Isolation Forest, like any tree ensemble method, is based on decision trees.\n",
    "\n",
    "In other words, Isolation Forest detects anomalies purely based on the fact that anomalies are data points that are few and different. The anomalies isolation is implemented without employing any distance or density measure.\n",
    "\n",
    "When applying an IsolationForest model, we set contamination = outliers_fraction, that is telling the model what proportion of outliers are present in the data. This is a trial/error metric.\n",
    "Fit and predict (data) performs outlier detection on data, and returns 1 for normal, -1 for the anomaly.\n",
    "Finally, we visualize anomalies with the Time Series view.\n",
    "Let’s do it step by step. First, visualize the time series data:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the algorithm did a pretty good job in identifying our planted anomalies, but it also labeled a few points at the start as “outlier”. This is due to two reasons:\n",
    "\n",
    "At the start, the algorithm is pretty naive to be able to comprehend what qualifies as an anomaly. The more data it gets, the more variance it’s able to see, and it adjusts itself.\n",
    "If you see many true negatives, that means your contamination parameter is too high Conversely, if you don’t see the red dots where they should be, the contamination parameter is set too low.\n",
    "Pros\n",
    "\n",
    "The biggest advantage of this technique is you can introduce as many random variables or features as you like to make more sophisticated models.\n",
    "\n",
    "Cons\n",
    "\n",
    "The weakness is that a growing number of features can start to impact your computational performance fairly quickly. In this case, you should select features carefully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## oneclass svm and isolation forest\n",
    "# LOF (Local Outlier Factor): Detects anomalies by evaluating the local density deviation of data points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see, Outliers are easier to isolate, while Inliers are harders to isolate.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the algorithm tries to chase down the actuals. Though this might be a good forecast where the error is low but the anomalous behaviour in the actuals cant be identified using this.\n",
    "\n",
    "This is a problem of using forecasting techniques for anomaly detection.We are trying to capture trends/seasonality in data along with not optimising too much on the error to get an exact replica of actuals(which makes us difficult to find anomalies).\n",
    "\n",
    "Every metric needs to be validated with parameters fine-tuned so that anomalies are detected when using forecasting for detecting anomalies. Also for metrics with different distribution of data a different approach in identifying anomalies needs to be followed.\n",
    "\n",
    "One more con is, Isolation forest we detected anomalies for a use case which comprised of multiple metrics at a time and we drilled down to anomalies on individual metrics in them.Whereas using forecasting mechanism we need a separate correlation logic as forecasting is individual for metrics.\n",
    "\n",
    "Whereas an algorithm like isolation forest separates out anomalous behavior from the data which can be used to generalize to multiple metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import plotly.graph_objects as go\n",
    "import plotly.subplots as sp\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from plotly.subplots import make_subplots\n",
    "from plot_anomaly import multivariate_anomaly_plot\n",
    "\n",
    "# Load your data (replace this with your actual data loading step)\n",
    "# For demonstration, let's generate sample data similar to your distribution\n",
    "data = pd.read_csv(\"times_series_data_no_labels.csv\" ,\n",
    "    index_col='datetime',\n",
    "    parse_dates=['datetime']\n",
    "    )\n",
    "\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iso_forest = IsolationForest(contamination=0.005, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "data['anomaly'] = iso_forest.fit_predict(data[['data_0', 'data_1']])\n",
    "data.loc[:, 'is_anomaly'] = data['anomaly'].apply(lambda x: True if x == -1 else False)\n",
    "\n",
    "multivariate_anomaly_plot(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Isolation forest - Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ", n_estimators=200, max_samples=0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"times_series_data_no_labels.csv\" ,\n",
    "    index_col='datetime',\n",
    "    parse_dates=['datetime']\n",
    "    )\n",
    "\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "window = 288\n",
    "data['hour'] = data.index.hour\n",
    "data['minute'] = data.index.minute\n",
    "data['timestamp'] = data['hour'] * 60 + data['minute']\n",
    "data['lag1_sensor1'] = data['data_0'].shift(1)\n",
    "data['lag1_sensor2'] = data['data_1'].shift(1)\n",
    "\n",
    "data['lag2_sensor1'] = data['data_0'].shift(2)\n",
    "data['lag2_sensor2'] = data['data_1'].shift(2)\n",
    "data['rolling_mean_sensor1'] = data['data_0'].rolling(window=window).mean()\n",
    "data['rolling_std_sensor1'] = data['data_0'].rolling(window=window).std()\n",
    "data['rolling_mean_sensor2'] = data['data_1'].rolling(window=window).mean()\n",
    "data['rolling_std_sensor2'] = data['data_1'].rolling(window=window).std()\n",
    "\n",
    "def night_time_indicator(dt):\n",
    "    if 23 <= dt.hour or dt.hour < 4:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "\n",
    "def ramp_up_down_time_indicator(dt):\n",
    "    if 4 <= dt.hour or dt.hour < 5:\n",
    "        return 3\n",
    "    elif 22 <= dt.hour or dt.hour < 23 :\n",
    "        return 2\n",
    "\n",
    "# Apply the function to the index and create a new column\n",
    "data['daytime_indicator'] = data.index.map(night_time_indicator)\n",
    "data['daytime_indicator'] = data.index.map(ramp_up_down_time_indicator)\n",
    "\n",
    "# Drop NaN values\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "# Fit Isolation Forest\n",
    "features = ['data_0', \n",
    "            'data_1', \n",
    "            'lag1_sensor1', 'lag1_sensor2', \n",
    "            'lag2_sensor1', 'lag2_sensor2', \n",
    "            # \"hour\", \"minute\",\n",
    "            # \"timestamp\",\n",
    "            \"daytime_indicator\",\n",
    "            # 'rolling_mean_sensor1', 'rolling_std_sensor1', 'rolling_mean_sensor2', 'rolling_std_sensor2'\n",
    "            ]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "np_scaled = scaler.fit_transform(data[features])\n",
    "data_scaled = pd.DataFrame(np_scaled)\n",
    "\n",
    "clf = IsolationForest(contamination=0.005, random_state=42)\n",
    "clf.fit(data_scaled)\n",
    "data['anomaly'] = clf.predict(data_scaled)\n",
    "\n",
    "# -1 for anomalies, 1 for normal\n",
    "\n",
    "data.loc[:, 'is_anomaly'] = data['anomaly'].apply(lambda x: True if x == -1 else False)\n",
    "\n",
    "multivariate_anomaly_plot(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another implementation of isolation forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"times_series_data_no_labels.csv\" ,\n",
    "    index_col='datetime',\n",
    "    parse_dates=['datetime']\n",
    "    )\n",
    "\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "np_scaled = scaler.fit_transform(data)\n",
    "\n",
    "data_scaled = pd.DataFrame(np_scaled)\n",
    "\n",
    "# Isolation forest \n",
    "outliers_fraction = 0.005\n",
    "ifo = IsolationForest(contamination = outliers_fraction)\n",
    "\n",
    "ifo.fit(data_scaled)\n",
    "data['anomaly'] = ifo.predict(data_scaled)\n",
    "\n",
    "\n",
    "data.loc[:, 'is_anomaly'] = data['anomaly'].apply(lambda x: True if x == -1 else False)\n",
    "\n",
    "multivariate_anomaly_plot(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detection using Forecasting\n",
    "Anomaly detection using Forecasting is based on an approach that several points from the past generate a forecast of the next point with the addition of some random variable, which is usually white noise. \n",
    "\n",
    "As you can imagine, forecasted points in the future will generate new points and so on. Its obvious effect on the forecast horizon – the signal gets smoother.\n",
    "\n",
    "The difficult part of using this method is that you should select the number of differences, number of autoregressions, and forecast error coefficients.\n",
    "\n",
    "Each time you work with a new signal, you should build a new forecasting model.\n",
    "\n",
    "Another obstacle is that your signal should be stationary after differencing. In simple words, it means your signal shouldn’t be dependent on time, which is a significant constraint.\n",
    "\n",
    "We can utilize different forecasting methods such as Moving Averages, Autoregressive approach, and ARIMA with its different variants. The procedure for detecting anomalies with ARIMA is:\n",
    "\n",
    "Predict the new point from past datums and find the difference in magnitude with those in the training data.\n",
    "Choose a threshold and identify anomalies based on that difference threshold. That’s it!\n",
    "To test this technique, we’re gonna use a popular module in time series called fbprophet. This module specifically caters to stationarity and seasonality, and can be tuned with some hyper-parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pros\n",
    "\n",
    "This algorithm nicely handles different seasonality parameters like monthly or yearly, and it has native support for all time series metrics. \n",
    "\n",
    "If you look closely, this algorithm can handle edge cases well as compared to the Isolation Forest algorithm.\n",
    "\n",
    "Cons\n",
    "\n",
    "Since this technique is based on forecasting, it will struggle in limited data scenarios. The quality of prediction in limited data will be lower, and so will the accuracy of anomaly detection.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
