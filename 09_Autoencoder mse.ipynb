{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why do we apply dimensionality reduction to find outliers?\n",
    "Don’t we lose some information, including the outliers, if we reduce the dimensionality? The answer is that once the main patterns are identified, the outliers are revealed. Many distance-based techniques (e.g. KNNs) suffer the curse of dimensionality when they compute distances of every data point in the full feature space. High dimensionality has to be reduced. \n",
    "\n",
    "Interestingly, during the process of dimensionality reduction outliers are identified. We can say outlier detection is a by-product of dimension reduction.\n",
    "\n",
    "Autoencoders are an unsupervised approach to find anomalies.\n",
    "\n",
    "Why autoencoders?\n",
    "There are many useful tools, such as Principal Component Analysis (PCA), for detecting outliers. Why do we need autoencoders? The reason is that PCA uses linear algebra to transform. In contrast, autoencoder techniques can perform non-linear transformations with their non-linear activation function and multiple layers. It’s more efficient to train several layers with an autoencoder, rather than training one huge transformation with PCA. The autoencoder techniques thus show their merits when the data problems are complex and non-linear in nature.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vn/miniconda3/envs/dlr/lib/python3.9/site-packages/torch/cuda/__init__.py:118: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at /opt/conda/conda-bld/pytorch_1716905971093/work/c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import optuna\n",
    "import json\n",
    "\n",
    "TIME_STEPS = 30\n",
    "BATCH_SIZE = 512\n",
    "EPOCHS = 100\n",
    "LEARNING_RATE = 0.01\n",
    "LATENT_DIM = 4\n",
    "EARLY_STOPPING_PATIENCE = 20\n",
    "\n",
    "# Check for GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Load data\n",
    "data_org = pd.read_csv(\"times_series_data_no_labels.csv\", index_col='datetime', parse_dates=['datetime'])\n",
    "\n",
    "def preprocess_data(column_name):\n",
    "    # Removing rows with values greater than 32 and less than 19\n",
    "    data = data_org[(data_org[column_name] <= 32) & (data_org[column_name] >= 19)]\n",
    "\n",
    "    # Removing rows for the time between 5:45 and 21:00 with values less than 26\n",
    "    data['hour'] = data.index.hour\n",
    "    data['minute'] = data.index.minute\n",
    "\n",
    "    condition_time = ~((data['hour'] > 5) & ((data['hour'] < 21) | ((data['hour'] == 21) & (data['minute'] == 0))) & (data[column_name] < 26))\n",
    "    data = data[condition_time]\n",
    "\n",
    "    # Dropping the additional columns used for filtering\n",
    "    data.drop(columns=['hour', 'minute'], inplace=True)\n",
    "\n",
    "    # Removing rows for the time between 00:10 and 03:05 with values greater than 22.5\n",
    "    data['hour'] = data.index.hour\n",
    "    data['minute'] = data.index.minute\n",
    "\n",
    "    condition_night = ~((data['hour'] == 0) & (data['minute'] >= 10) |\n",
    "                        (data['hour'] > 0) & (data['hour'] < 3) |\n",
    "                        (data['hour'] == 3) & (data['minute'] <= 5) &\n",
    "                        (data[column_name] > 22.5))\n",
    "    data = data[condition_night]\n",
    "\n",
    "    # Dropping the additional columns used for filtering\n",
    "    data.drop(columns=['hour', 'minute'], inplace=True)\n",
    "\n",
    "    # Split data into training and test sets\n",
    "    train_size = int(len(data) * 0.85)\n",
    "    train, test = data.iloc[0:train_size], data.iloc[train_size:len(data)]\n",
    "\n",
    "    return train, test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_559081/4066206803.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['hour'] = data.index.hour\n",
      "/tmp/ipykernel_559081/4066206803.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['minute'] = data.index.minute\n",
      "/tmp/ipykernel_559081/4066206803.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['hour'] = data.index.hour\n",
      "/tmp/ipykernel_559081/4066206803.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['minute'] = data.index.minute\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_0, test_0 = preprocess_data('data_0')\n",
    "train_1, test_1 = preprocess_data('data_1')\n",
    "\n",
    "def create_dataset(X, time_steps=1):\n",
    "    Xs = []\n",
    "    for i in range(len(X) - time_steps):\n",
    "        v = X.iloc[i:(i + time_steps)].values\n",
    "        Xs.append(v)\n",
    "    return np.array(Xs)\n",
    "\n",
    "def normalize_data(data, min_val, max_val):\n",
    "    return (data - min_val) / (max_val - min_val)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class DenseEncoder(nn.Module):\n",
    "    def __init__(self, input_shape: int, latent_dim: int):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(in_features=input_shape, out_features=4 * latent_dim)\n",
    "        self.l2 = nn.Linear(in_features=4 * latent_dim, out_features=2 * latent_dim)\n",
    "        self.l3 = nn.Linear(in_features=2 * latent_dim, out_features=latent_dim)\n",
    "\n",
    "    def forward(self, inputs: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.l1(inputs)\n",
    "        x = torch.relu(x)\n",
    "        x = self.l2(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.l3(x)\n",
    "        latent = torch.relu(x)\n",
    "        return latent\n",
    "\n",
    "\n",
    "class DenseDecoder(nn.Module):\n",
    "    def __init__(self, output_shape: int, latent_dim: int):\n",
    "        super().__init__()\n",
    "        self.l4 = nn.Linear(in_features=latent_dim, out_features=2 * latent_dim)\n",
    "        self.l5 = nn.Linear(in_features=2 * latent_dim, out_features=4 * latent_dim)\n",
    "        self.output = nn.Linear(in_features=4 * latent_dim, out_features=output_shape)\n",
    "\n",
    "    def forward(self, latent: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.l4(latent)\n",
    "        x = torch.relu(x)\n",
    "        x = self.l5(x)\n",
    "        x = torch.relu(x)\n",
    "        output = self.output(x)\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "class DenseAutoencoderModel(nn.Module):\n",
    "    def __init__(self, input_shape, latent_dim):\n",
    "        super(DenseAutoencoderModel, self).__init__()\n",
    "        self.encoder = DenseEncoder(input_shape, latent_dim)\n",
    "        self.decoder = DenseDecoder(input_shape, latent_dim)\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        inputs = inputs.squeeze(2)\n",
    "        latent = self.encoder(inputs)\n",
    "        output = self.decoder(latent)\n",
    "        output = output.unsqueeze(2)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, criterion, optimizer, epochs, patience):\n",
    "    best_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for df in train_loader:\n",
    "            df = df[0].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(df)\n",
    "            loss = criterion(output, df)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        train_loss /= len(train_loader)\n",
    "        print(f'Epoch {epoch+1}, Loss: {train_loss}')\n",
    "\n",
    "        if train_loss < best_loss:\n",
    "            best_loss = train_loss\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        if epochs_no_improve == patience:\n",
    "            print('Early stopping!')\n",
    "            break\n",
    "\n",
    "    return best_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def objective(trial, train_loader):\n",
    "    latent_dim = trial.suggest_int('latent_dim', 2, 12)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-4, 1e-2, log=True)\n",
    "    \n",
    "    model = DenseAutoencoderModel(input_shape=TIME_STEPS, latent_dim=latent_dim).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    final_loss = train_model(model, train_loader, criterion, optimizer, EPOCHS, EARLY_STOPPING_PATIENCE)\n",
    "    \n",
    "    return final_loss\n",
    "\n",
    "def run_optuna(train_loader):\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(lambda trial: objective(trial, train_loader), n_trials=50)\n",
    "    best_params = study.best_params\n",
    "    print(f'Best hyperparameters: {best_params}')\n",
    "    return best_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_and_train(train, column_name):\n",
    "    train_col = pd.DataFrame(train, columns=[column_name])\n",
    "\n",
    "    TIME_STEPS = 30\n",
    "    BATCH_SIZE = 512\n",
    "    EPOCHS = 100\n",
    "    EARLY_STOPPING_PATIENCE = 20\n",
    "\n",
    "    X_train = create_dataset(train_col, TIME_STEPS)\n",
    "\n",
    "    min_val = X_train.min()\n",
    "    max_val = X_train.max()  # Use train max for consistency\n",
    "\n",
    "    train_data = normalize_data(X_train, min_val, max_val)\n",
    "\n",
    "    train_tensor = torch.tensor(train_data, dtype=torch.float32).to(device)\n",
    "\n",
    "    train_loader = DataLoader(TensorDataset(train_tensor), batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "    best_params = run_optuna(train_loader)\n",
    "\n",
    "    with open(f'saves/best_hyperparameters_{column_name}.json', 'w') as f:\n",
    "        json.dump(best_params, f)\n",
    "\n",
    "    model = DenseAutoencoderModel(input_shape=TIME_STEPS, latent_dim=best_params['latent_dim']).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=best_params['learning_rate'])\n",
    "\n",
    "    final_loss = train_model(model, train_loader, criterion, optimizer, EPOCHS, EARLY_STOPPING_PATIENCE)\n",
    "    print(f'Final model training loss for {column_name}: {final_loss}')\n",
    "\n",
    "    torch.save(model.state_dict(), f'saves/best_autoencoder_model_{column_name}.pth')\n",
    "    print(f'Best model for {column_name} saved!')\n",
    "\n",
    "    return model, min_val, max_val, best_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "# criterion = nn.L1Loss()\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# os.makedirs('saves', exist_ok=True)\n",
    "\n",
    "# # Train models for data_0 and data_1\n",
    "# model_0, min_val_0, max_val_0, best_params_0 = preprocess_and_train(train_0, 'data_0')\n",
    "# model_1, min_val_1, max_val_1, best_params_1 = preprocess_and_train(train_1, 'data_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_anomalies(column_name, model, min_val, max_val, threshold):\n",
    "    # Create a windowed dataset for the specified column\n",
    "    data_window = create_dataset(data_org[[column_name]], TIME_STEPS)\n",
    "    \n",
    "    # Scale the data\n",
    "    data_window_scale = (data_window - min_val) / (max_val - min_val)\n",
    "    \n",
    "    # Convert to PyTorch tensor\n",
    "    data_window_scale = torch.tensor(data_window_scale, dtype=torch.float32).to(device)\n",
    "    \n",
    "    # Create a DataLoader\n",
    "    data_loader = torch.utils.data.DataLoader(data_window_scale, batch_size=1, shuffle=False)\n",
    "    \n",
    "    # Calculate reconstruction losses\n",
    "    reconstruction_loss = []\n",
    "    with torch.no_grad():\n",
    "        for df in data_loader:\n",
    "            df = df.to(device)\n",
    "            output = model(df)\n",
    "            loss = criterion(output, df)\n",
    "            reconstruction_loss.append(loss.item())\n",
    "    \n",
    "    # Convert to numpy array\n",
    "    array_of_values = np.array(reconstruction_loss)\n",
    "    \n",
    "    # Identify anomalies\n",
    "    is_anomaly = array_of_values > threshold\n",
    "    \n",
    "    # Prepare column name for anomaly flag\n",
    "    anomaly_column = f\"is_anomaly_{column_name.split('_')[1]}\"\n",
    "    data_org[anomaly_column] = False\n",
    "    \n",
    "    # Calculate the starting index for updating the original DataFrame\n",
    "    n = len(is_anomaly)\n",
    "    start_idx = -(n + 5)\n",
    "    if start_idx < 0:\n",
    "        start_idx = max(len(data_org) + start_idx, 0)\n",
    "    \n",
    "    # Get the rows to update\n",
    "    rows_to_update = data_org.index[start_idx:start_idx + n]\n",
    "    \n",
    "    # Update the DataFrame with anomaly information\n",
    "    data_org.loc[rows_to_update, anomaly_column] = is_anomaly\n",
    "    \n",
    "    return reconstruction_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold_0 = 0.0025  # Set threshold for data_0\n",
    "# threshold_1 = 0.00225  # Set threshold for data_1\n",
    "\n",
    "# with open('saves/best_hyperparameters_data_0.json', 'r') as f:\n",
    "#     best_params = json.load(f)\n",
    "# model_0 = DenseAutoencoderModel(input_shape=TIME_STEPS, latent_dim=best_params['latent_dim']).to(device)\n",
    "# optimizer_0 = optim.Adam(model_0.parameters(), lr=best_params['learning_rate'])\n",
    "\n",
    "# with open('saves/best_hyperparameters_data_1.json', 'r') as f:\n",
    "#     best_params = json.load(f)\n",
    "\n",
    "# model_1 = DenseAutoencoderModel(input_shape=TIME_STEPS, latent_dim=best_params['latent_dim']).to(device)\n",
    "# optimizer_1 = optim.Adam(model_1.parameters(), lr=best_params['learning_rate'])\n",
    "\n",
    "# # final_loss = train_model(model, train_loader, criterion, optimizer, EPOCHS, EARLY_STOPPING_PATIENCE)\n",
    "\n",
    "# model_0.load_state_dict(torch.load('saves/best_autoencoder_model_data_0.pth'))\n",
    "# model_1.load_state_dict(torch.load('saves/best_autoencoder_model_data_0.pth'))\n",
    "\n",
    "# reconstruction_loss_0 = calculate_anomalies('data_0', model_0, min_val_0, max_val_0, threshold_0)\n",
    "# reconstruction_loss_1 = calculate_anomalies('data_1', model_1, min_val_1, max_val_1, threshold_1)\n",
    "\n",
    "# # Plot histograms\n",
    "# plt.hist(reconstruction_loss_0, bins=100)\n",
    "# plt.xlabel('Loss')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.title('Histogram of Reconstruction Losses for data_0')\n",
    "# plt.show()\n",
    "\n",
    "# plt.hist(reconstruction_loss_1, bins=100)\n",
    "# plt.xlabel('Loss')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.title('Histogram of Reconstruction Losses for data_1')\n",
    "# plt.show()\n",
    "\n",
    "# # Plot anomalies\n",
    "# from plot_anomaly import univariate_anomaly_plot\n",
    "# univariate_anomaly_plot(data=data_org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 17\u001b[0m\n\u001b[1;32m     13\u001b[0m optimizer_1 \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model_1\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mbest_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# final_loss = train_model(model, train_loader, criterion, optimizer, EPOCHS, EARLY_STOPPING_PATIENCE)\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m model_0\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msaves/best_autoencoder_model_data_0.pth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     18\u001b[0m model_1\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msaves/best_autoencoder_model_data_0.pth\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     20\u001b[0m reconstruction_loss_0 \u001b[38;5;241m=\u001b[39m calculate_anomalies(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata_0\u001b[39m\u001b[38;5;124m'\u001b[39m, model_0, min_val_0, max_val_0, threshold_0)\n",
      "File \u001b[0;32m~/miniconda3/envs/dlr/lib/python3.9/site-packages/torch/serialization.py:1025\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1023\u001b[0m             \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1024\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1025\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1026\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1027\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1028\u001b[0m \u001b[43m                     \u001b[49m\u001b[43moverall_storage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverall_storage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1029\u001b[0m \u001b[43m                     \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1030\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mmap:\n\u001b[1;32m   1031\u001b[0m     f_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(f, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/dlr/lib/python3.9/site-packages/torch/serialization.py:1446\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1444\u001b[0m unpickler \u001b[38;5;241m=\u001b[39m UnpicklerWrapper(data_file, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[1;32m   1445\u001b[0m unpickler\u001b[38;5;241m.\u001b[39mpersistent_load \u001b[38;5;241m=\u001b[39m persistent_load\n\u001b[0;32m-> 1446\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1448\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_validate_loaded_sparse_tensors()\n\u001b[1;32m   1449\u001b[0m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_log_api_usage_metadata(\n\u001b[1;32m   1450\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.load.metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mserialization_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: zip_file\u001b[38;5;241m.\u001b[39mserialization_id()}\n\u001b[1;32m   1451\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/dlr/lib/python3.9/site-packages/torch/serialization.py:1416\u001b[0m, in \u001b[0;36m_load.<locals>.persistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   1414\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1415\u001b[0m     nbytes \u001b[38;5;241m=\u001b[39m numel \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_element_size(dtype)\n\u001b[0;32m-> 1416\u001b[0m     typed_storage \u001b[38;5;241m=\u001b[39m \u001b[43mload_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_maybe_decode_ascii\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1418\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m typed_storage\n",
      "File \u001b[0;32m~/miniconda3/envs/dlr/lib/python3.9/site-packages/torch/serialization.py:1390\u001b[0m, in \u001b[0;36m_load.<locals>.load_tensor\u001b[0;34m(dtype, numel, key, location)\u001b[0m\n\u001b[1;32m   1385\u001b[0m         storage\u001b[38;5;241m.\u001b[39mbyteswap(dtype)\n\u001b[1;32m   1387\u001b[0m \u001b[38;5;66;03m# TODO: Once we decide to break serialization FC, we can\u001b[39;00m\n\u001b[1;32m   1388\u001b[0m \u001b[38;5;66;03m# stop wrapping with TypedStorage\u001b[39;00m\n\u001b[1;32m   1389\u001b[0m typed_storage \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstorage\u001b[38;5;241m.\u001b[39mTypedStorage(\n\u001b[0;32m-> 1390\u001b[0m     wrap_storage\u001b[38;5;241m=\u001b[39m\u001b[43mrestore_location\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   1391\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m   1392\u001b[0m     _internal\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1394\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typed_storage\u001b[38;5;241m.\u001b[39m_data_ptr() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1395\u001b[0m     loaded_storages[key] \u001b[38;5;241m=\u001b[39m typed_storage\n",
      "File \u001b[0;32m~/miniconda3/envs/dlr/lib/python3.9/site-packages/torch/serialization.py:390\u001b[0m, in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_restore_location\u001b[39m(storage, location):\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, _, fn \u001b[38;5;129;01min\u001b[39;00m _package_registry:\n\u001b[0;32m--> 390\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    391\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    392\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/envs/dlr/lib/python3.9/site-packages/torch/serialization.py:265\u001b[0m, in \u001b[0;36m_cuda_deserialize\u001b[0;34m(obj, location)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_cuda_deserialize\u001b[39m(obj, location):\n\u001b[1;32m    264\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m location\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 265\u001b[0m         device \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_cuda_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    266\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_torch_load_uninitialized\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    267\u001b[0m             \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice(device):\n",
      "File \u001b[0;32m~/miniconda3/envs/dlr/lib/python3.9/site-packages/torch/serialization.py:249\u001b[0m, in \u001b[0;36mvalidate_cuda_device\u001b[0;34m(location)\u001b[0m\n\u001b[1;32m    246\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_get_device_index(location, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[0;32m--> 249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAttempting to deserialize object on a CUDA \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    250\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice but torch.cuda.is_available() is False. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    251\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIf you are running on a CPU-only machine, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    252\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplease use torch.load with map_location=torch.device(\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    253\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mto map your storages to the CPU.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    254\u001b[0m device_count \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice_count()\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m device_count:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU."
     ]
    }
   ],
   "source": [
    "# threshold_0 = 0.0025  # Set threshold for data_0\n",
    "# threshold_1 = 0.00225  # Set threshold for data_1\n",
    "\n",
    "# reconstruction_loss_0 = calculate_anomalies('data_0', model_0, min_val_0, max_val_0, threshold_0)\n",
    "# reconstruction_loss_1 = calculate_anomalies('data_1', model_1, min_val_1, max_val_1, threshold_1)\n",
    "\n",
    "# # Plot histograms\n",
    "# plt.hist(reconstruction_loss_0, bins=100)\n",
    "# plt.xlabel('Loss')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.title('Histogram of Reconstruction Losses for data_0')\n",
    "# plt.show()\n",
    "\n",
    "# plt.hist(reconstruction_loss_1, bins=100)\n",
    "# plt.xlabel('Loss')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.title('Histogram of Reconstruction Losses for data_1')\n",
    "# plt.show()\n",
    "\n",
    "# # Plot anomalies\n",
    "# from plot_anomaly import univariate_anomaly_plot\n",
    "# univariate_anomaly_plot(data=data_org)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This way, we can distinguish and label pretty perfectly between typical datums and anomalies.\n",
    "\n",
    "Pros\n",
    "\n",
    "Autoencoders can handle high-dimensional data with ease. \n",
    "Pertaining to its nonlinearity behavior, it can find complex patterns within high-dimensional datasets.\n",
    "Cons\n",
    "\n",
    "Since it’s a deep learning-based strategy, it will particularly struggle if the data is less.\n",
    "Computation costs will skyrocket if the depth of the network increases and while dealing with big data.\n",
    "So far we’ve seen how to detect and identify anomalies. But the real question arises after finding them. Now what? What do we do about it?\n",
    "\n",
    "Let’s discuss some of the pointers you could apply in your scenario."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
